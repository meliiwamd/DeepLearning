{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hw4DeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-72_AczN5vwf"
      },
      "source": [
        "Melika Ahmadi Ranjbar 97521036\n",
        "\n",
        "---\n",
        "Homework 4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFozgw8H50Y1"
      },
      "source": [
        "#Question 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d_YT0nK5hz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "536d18d7-3ccd-4cf6-978c-3fa486e86a75"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "# Load Dataset & Data Augmentation\n",
        "transformTrain = transforms.Compose(\n",
        "    [transforms.RandomCrop(32, padding=4),\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.RandomAffine(degrees=10, scale=(.9, 1.1), shear=0),\n",
        "    #  transforms.RandomPerspective(distortion_scale=0.2),\n",
        "     transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
        "     transforms.RandomRotation(30),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "transformTest = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transformTrain)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transformTest)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = [\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHjV-bEOo4nn"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=20, out_channels=36, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=36, out_channels=72, kernel_size=3, padding=2),\n",
        "            nn.BatchNorm2d(72),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=72, out_channels=120, kernel_size=3, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(120 * 6 * 6, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    "
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVqQDZR348DT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb15a6c-5125-43d9-d2d5-13381d19e3cb"
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "Model = Network()\n",
        "\n",
        "Cuda = torch.cuda.is_available()\n",
        "if Cuda:\n",
        "    print('CUDA available, GPU started')\n",
        "    Model = Network().cuda()\n",
        "    Model = torch.nn.DataParallel(Model, device_ids=range(torch.cuda.device_count()))\n",
        "else:\n",
        "    print('No CUDA available, Continue With CPU')\n",
        "\n",
        "Loss = nn.CrossEntropyLoss()\n",
        "Optimizer = optim.Adam(Model.parameters(), lr=0.001, weight_decay=0.005)\n",
        "\n",
        "\n",
        "\n",
        "for Epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "    total_train = 0\n",
        "    correct_train = 0\n",
        "    train_accuracy = 0\n",
        "    for i, data in enumerate(trainloader, start=0):\n",
        "        # Input Data [Inputs, Labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        if Cuda:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        # Zero Gradient's Parameters\n",
        "        Optimizer.zero_grad()\n",
        "\n",
        "        # Forward, Backward, Optimize\n",
        "        outputs = Model(inputs)\n",
        "        loss = Loss(outputs, labels)\n",
        "        loss.backward()\n",
        "        Optimizer.step()\n",
        "\n",
        "         # accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += predicted.eq(label.data).sum().item()\n",
        "        train_accuracy = 100 * correct_train / total_train\n",
        "\n",
        "        # Statics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                    (Epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "    print('Epoch\\'s Loss: ', running_loss)\n",
        "    print('Epoch\\'s Accuracy: ', train_accuracy)\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available, GPU started\n",
            "[1,  2000] loss: 2.242\n",
            "[1,  4000] loss: 2.124\n",
            "[1,  6000] loss: 2.080\n",
            "[1,  8000] loss: 2.041\n",
            "[1, 10000] loss: 2.017\n",
            "[1, 12000] loss: 1.994\n",
            "Epoch's Loss:  1000.3922016620636\n",
            "Epoch's Accuracy:  13.046\n",
            "[2,  2000] loss: 1.980\n",
            "[2,  4000] loss: 1.984\n",
            "[2,  6000] loss: 1.961\n",
            "[2,  8000] loss: 1.959\n",
            "[2, 10000] loss: 1.932\n",
            "[2, 12000] loss: 1.955\n",
            "Epoch's Loss:  958.9149264097214\n",
            "Epoch's Accuracy:  12.966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNrCnSFaw2ut",
        "outputId": "caf6d17d-a62e-4685-a723-860a5a919f84"
      },
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "Model.eval()\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        if Cuda:\n",
        "            images = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        outputs = Model(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predictions == labels).sum().item()\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "print('Total Accuracy: ', 100 * correct / total)\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                   accuracy))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Accuracy:  10.2\n",
            "Accuracy for class plane is: 26.0 %\n",
            "Accuracy for class car   is: 23.8 %\n",
            "Accuracy for class bird  is: 0.0 %\n",
            "Accuracy for class cat   is: 0.0 %\n",
            "Accuracy for class deer  is: 0.0 %\n",
            "Accuracy for class dog   is: 0.0 %\n",
            "Accuracy for class frog  is: 27.1 %\n",
            "Accuracy for class horse is: 0.0 %\n",
            "Accuracy for class ship  is: 0.0 %\n",
            "Accuracy for class truck is: 25.1 %\n"
          ]
        }
      ]
    }
  ]
}